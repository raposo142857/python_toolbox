{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importações de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacoes de bibliotecas\n",
    "\n",
    "import pandas as pd # Analise de dados\n",
    "from datetime import datetime, timedelta # Lidar om datas (diferencas, conversoes, etc.)\n",
    "from dateutil.relativedelta import relativedelta # Tambem de lidar com datas\n",
    "import statsmodels.api as sm # Biblioteca de onde vem a funcao para regressao (OLS)\n",
    "from itertools import combinations # Funcao para iterar entre possiveis listas (para otimizar o AIC)\n",
    "from random import randint\n",
    "\n",
    "# Funcoes para aprendizado de maquina, ainda nao foi tao util\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from scipy import stats # Biblioteca para algumas metricas estatisticas, como trimmed mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor AIC: 136.55658647059678\n",
      "Melhor Modelo:                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  churn   R-squared:                       0.082\n",
      "Model:                            OLS   Adj. R-squared:                  0.072\n",
      "Method:                 Least Squares   F-statistic:                     8.715\n",
      "Date:                Wed, 20 Dec 2023   Prob (F-statistic):            0.00395\n",
      "Time:                        09:48:57   Log-Likelihood:                -66.278\n",
      "No. Observations:                 100   AIC:                             136.6\n",
      "Df Residuals:                      98   BIC:                             141.8\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2600      0.067      3.877      0.000       0.127       0.393\n",
      "brinde         0.2800      0.095      2.952      0.004       0.092       0.468\n",
      "==============================================================================\n",
      "Omnibus:                      244.938   Durbin-Watson:                   1.882\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               11.560\n",
      "Skew:                           0.350   Prob(JB):                      0.00309\n",
      "Kurtosis:                       1.489   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Acurácia: 0.6\n",
      "Matriz de Confusão:\n",
      "[[9 2]\n",
      " [6 3]]\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.82      0.69        11\n",
      "           1       0.60      0.33      0.43         9\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.60      0.58      0.56        20\n",
      "weighted avg       0.60      0.60      0.57        20\n",
      "\n",
      "Previsão de Churn: 1\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "######################### ESCOLHA DE VARIAVEIS RELEVANTES #########################\n",
    "###################################################################################\n",
    "\n",
    "df_dict = {'sp': [randint(0, 1) for _ in range(100)],\n",
    "           'meses_cliente': [randint(1, 15) for _ in range(100)],\n",
    "           'idoso': [randint(0, 1) for _ in range(100)],\n",
    "           'brinde': [randint(0, 1) for _ in range(100)],\n",
    "           'churn': [randint(0, 1) for _ in range(100)]}\n",
    "\n",
    "df = pd.DataFrame(df_dict)\n",
    "\n",
    "### Regressao simples\n",
    "# Suponha que você tenha uma lista de variáveis explicativas\n",
    "variaveis_explicativas_list = ['sp', 'meses_cliente', 'idoso', 'brinde']\n",
    "\n",
    "# Inicialize uma lista para armazenar todas as combinações\n",
    "todas_combinacoes = []\n",
    "todas_combinacoes_list = []\n",
    "\n",
    "# Gere todas as combinações possíveis\n",
    "for r in range(1, len(variaveis_explicativas_list) + 1):\n",
    "    combinacoes = combinations(variaveis_explicativas_list, r)\n",
    "    todas_combinacoes.extend(combinacoes)\n",
    "\n",
    "# Agora, todas_combinacoes contém todas as combinações possíveis\n",
    "for combinacao in todas_combinacoes:\n",
    "    todas_combinacoes_list.append(list(combinacao))\n",
    "\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "# Suponha que você tenha um DataFrame df com seus dados\n",
    "X = df[variaveis_explicativas_list]  # Variáveis explicativas\n",
    "y = df['churn']  # Variável resposta\n",
    "\n",
    "# Inicialize variáveis para armazenar o melhor modelo e seu AIC\n",
    "melhor_modelo = None\n",
    "melhor_aic = float('inf')\n",
    "\n",
    "# Lista de combinacoes possiveis de variaveis\n",
    "lista_de_combinacoes_de_variaveis = todas_combinacoes_list\n",
    "\n",
    "# Loop sobre os modelos candidatos\n",
    "for variaveis_explicativas in lista_de_combinacoes_de_variaveis:\n",
    "    modelo = sm.OLS(y, sm.add_constant(X[variaveis_explicativas])).fit()  # Ajustar o modelo\n",
    "    aic = modelo.aic  # Calcular o AIC\n",
    "\n",
    "    # Verificar se o AIC é menor do que o melhor AIC atual\n",
    "    if aic < melhor_aic:\n",
    "        melhor_aic = aic\n",
    "        melhor_modelo = modelo\n",
    "\n",
    "# O melhor modelo e seu AIC estarão armazenados em melhor_modelo e melhor_aic\n",
    "print(\"Melhor AIC:\", melhor_aic)\n",
    "print(\"Melhor Modelo:\", melhor_modelo.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modelo com as variaveis que me vieram a telha (para teste de predição)\n",
    "\n",
    "modelo_use = sm.OLS(y, sm.add_constant(X[['sp', 'brinde']])).fit()\n",
    "parametros = modelo_use.params\n",
    "entrada = {'sp': 1, 'meses_cliente': 0, 'brinde': 0}\n",
    "churn = parametros.const + parametros.sp*entrada['sp']  + parametros.brinde*entrada['brinde']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### TESTE - APRENDIZADO DE MAQUINA ######\n",
    "\n",
    "# Divida os dados em conjuntos de treinamento e teste\n",
    "X = df[['sp', 'meses_cliente', 'idoso', 'brinde']]\n",
    "y = df['churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crie e treine o modelo de Regressão Logística\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Faça previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avalie o desempenho do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion)\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(report)\n",
    "\n",
    "\n",
    "# Suponha que você já tenha treinado o modelo e armazenado em 'model'\n",
    "\n",
    "def prever_churn(model, sp, meses_cliente, idoso, brinde):\n",
    "    # Crie um DataFrame com os parâmetros fornecidos\n",
    "    dados = pd.DataFrame({'sp': [sp], 'meses_cliente': [meses_cliente], 'idoso': [idoso], 'brinde': [brinde]})\n",
    "    \n",
    "    # Faça a previsão usando o modelo\n",
    "    previsao = model.predict(dados)\n",
    "    \n",
    "    # Retorne a previsão (0 ou 1)\n",
    "    return previsao[0]\n",
    "\n",
    "# Exemplo de uso da função\n",
    "churn_previsto = prever_churn(model, sp=0, meses_cliente=0, idoso=1, brinde=1)\n",
    "\n",
    "print(\"Previsão de Churn:\", churn_previsto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
